# CSCA5622: Introduction to Machine Learning - Supervised Learning

This course provides a foundational understanding of supervised learning methods using Python, based on the textbook "Introduction to Statistical Learning with Python" (ISLP).

## Directory Structure

### üìö ISLP/ - Textbook Notes
Comprehensive chapter-by-chapter notes following the ISLP textbook structure. Each chapter file contains detailed notes, examples, and key concepts.

### üéì Lecture_Notes/ - Course Lectures
Notes from class lectures, organized chronologically. Use naming convention: `Lecture_XX_Topic.md`

### üíª Projects/ - Course Projects
Implementation projects and assignments, each in its own subdirectory with code, documentation, and results.

---

## ISLP Textbook Structure & Documentation

The **Introduction to Statistical Learning with Python (ISLP)** textbook covers the fundamental concepts of statistical learning and machine learning. Below is the complete book structure with my documentation progress:

### ‚úÖ Chapter 1 - Introduction 
**Pages: 1-14** | **Status: Complete**
- Overview of statistical learning
- Goals: prediction vs. inference  
- Supervised vs. unsupervised learning
- Regression vs. classification problems

### ‚úÖ Chapter 2 - Statistical Learning
**Pages: 15-68** | **Status: Complete**
- **2.1** What Is Statistical Learning?
- **2.2** Assessing Model Accuracy
- **2.3** Lab: Introduction to Python
- **2.4** Exercises

### üìù Chapter 3 - Linear Regression
**Pages: 69-134** | **Status: Template Ready**
- **3.1** Simple Linear Regression
- **3.2** Multiple Linear Regression  
- **3.3** Other Considerations in the Regression Model
- **3.4** The Marketing Plan
- **3.5** Comparison of Linear Regression with K-Nearest Neighbors
- **3.6** Lab: Linear Regression
- **3.7** Exercises

### üìù Chapter 4 - Classification
**Pages: 135-200** | **Status: Template Ready**
- **4.1** An Overview of Classification
- **4.2** Why Not Linear Regression?
- **4.3** Logistic Regression
- **4.4** Generative Models for Classification
- **4.5** A Comparison of Classification Methods
- **4.6** Generalized Linear Models
- **4.7** Lab: Logistic Regression, LDA, QDA, and KNN
- **4.8** Exercises

### üìù Chapter 5 - Resampling Methods
**Pages: 201-228** | **Status: Template Ready**
- **5.1** Cross-Validation
- **5.2** The Bootstrap
- **5.3** Lab: Cross-Validation and the Bootstrap
- **5.4** Exercises

### üìù Chapter 6 - Linear Model Selection and Regularization
**Pages: 229-288** | **Status: Template Ready**
- **6.1** Subset Selection
- **6.2** Shrinkage Methods
- **6.3** Dimension Reduction Methods
- **6.4** Considerations in High Dimensions
- **6.5** Lab: Linear Models and Regularization Methods
- **6.6** Exercises

### üìù Chapter 7 - Moving Beyond Linearity
**Pages: 289-330** | **Status: Template Ready**
- **7.1** Polynomial Regression
- **7.2** Step Functions
- **7.3** Basis Functions
- **7.4** Regression Splines
- **7.5** Smoothing Splines
- **7.6** Local Regression
- **7.7** Generalized Additive Models
- **7.8** Lab: Non-Linear Modeling
- **7.9** Exercises

### üìù Chapter 8 - Tree-Based Methods
**Pages: 331-366** | **Status: Template Ready**
- **8.1** The Basics of Decision Trees
- **8.2** Bagging, Random Forests, Boosting, and Bayesian Additive Regression Trees
- **8.3** Lab: Tree-Based Methods
- **8.4** Exercises

### üìù Chapter 9 - Support Vector Machines
**Pages: 367-398** | **Status: Template Ready**
- **9.1** Maximal Margin Classifier
- **9.2** Support Vector Classifiers
- **9.3** Support Vector Machines
- **9.4** SVMs with More than Two Classes
- **9.5** Relationship to Logistic Regression
- **9.6** Lab: Support Vector Machines
- **9.7** Exercises

### üìù Chapter 10 - Deep Learning
**Pages: 399-468** | **Status: Template Ready**
- **10.1** Single Layer Neural Networks
- **10.2** Multilayer Neural Networks
- **10.3** Convolutional Neural Networks
- **10.4** Document Classification
- **10.5** Recurrent Neural Networks
- **10.6** When to Use Deep Learning
- **10.7** Fitting a Neural Network
- **10.8** Interpolation and Double Descent
- **10.9** Lab: Deep Learning
- **10.10** Exercises

### üìù Chapter 11 - Survival Analysis and Censored Data
**Pages: 469-502** | **Status: Template Ready**
- **11.1** Survival and Censoring Times
- **11.2** A Closer Look at Censoring
- **11.3** The Kaplan‚ÄìMeier Survival Curve
- **11.4** The Log-Rank Test
- **11.5** Regression Models With a Survival Response
- **11.6** Shrinkage for the Cox Model
- **11.7** Additional Topics
- **11.8** Lab: Survival Analysis
- **11.9** Exercises

### üìù Chapter 12 - Unsupervised Learning
**Pages: 503-556** | **Status: Template Ready**
- **12.1** The Challenge of Unsupervised Learning
- **12.2** Principal Components Analysis
- **12.3** Missing Values and Matrix Completion
- **12.4** Clustering Methods
- **12.5** Lab: Unsupervised Learning
- **12.6** Exercises

### üìù Chapter 13 - Multiple Testing
**Pages: 557-596** | **Status: Template Ready**
- **13.1** A Quick Review of Hypothesis Testing
- **13.2** The Challenge of Multiple Testing
- **13.3** The Family-Wise Error Rate
- **13.4** The False Discovery Rate
- **13.5** A Re-Sampling Approach to p-Values and False Discovery Rates
- **13.6** Lab: Multiple Testing
- **13.7** Exercises

---

## Documentation Approach

### Reading Strategy
1. **Pre-reading**: Review chapter template and learning objectives
2. **Active reading**: Take detailed notes in the corresponding chapter file
3. **Post-reading**: Complete exercises and create summary notes
4. **Integration**: Connect concepts across chapters and with lecture material

### Note-Taking Format
- **Concepts**: Clear definitions and explanations
- **Examples**: Practical applications and use cases
- **Code**: Python implementations and lab exercises
- **Insights**: Personal understanding and connections
- **Questions**: Areas needing clarification or further study

---

## Course Learning Objectives

By the end of this course, students should be able to:
1. Understand fundamental concepts of statistical learning
2. Implement supervised learning algorithms in Python
3. Evaluate and compare different machine learning models
4. Apply statistical learning methods to real-world problems
5. Interpret and communicate results effectively

## Key Python Libraries
- **NumPy**: Numerical computing
- **Pandas**: Data manipulation and analysis
- **Matplotlib/Seaborn**: Data visualization
- **Scikit-learn**: Machine learning algorithms
- **Statsmodels**: Statistical modeling
